{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "TP3_DL_auto-encoders.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9VUagMroNkj",
        "colab_type": "text"
      },
      "source": [
        "# **Machine Learning Lab 4EII - IA course**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdNqp46loNkm",
        "colab_type": "text"
      },
      "source": [
        "## 1- **Introduction**\n",
        "\n",
        "This lab aim at using **auto encoders** for diffrent applications such as image compression and image de-noising. The auto-encoder can be based on neural networks with dense layers or convolutional neural networks:  \n",
        "\n",
        "In this lab you will learn to:\n",
        "* Build you own auto-encoder based on NN and CNN.\n",
        "* Apply the auto-encoder for image denoising and compression.\n",
        "* Build a variational auto-encoder \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb0Ckwt51NSu",
        "colab_type": "text"
      },
      "source": [
        "## 2- **Module importation**\n",
        "Import some useful and common python modules "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hxU_LEZoNko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "import progressbar\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc7KsfZWoNks",
        "colab_type": "text"
      },
      "source": [
        "## 3- **Download and study the the MNIST dataset**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHOn5QhATNph",
        "colab_type": "text"
      },
      "source": [
        "### 3.a - Download the MNIST dataset\n",
        "\n",
        "MNIST dataset contains 70000 images of handwritten digits from 0 to 9. The dataset contains images of size 28x28 pixels and the corresponding labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcNOgG4E4z3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = fetch_openml('mnist_784') #You can also use and test mnist_784 or Fashion-MNIST dataset  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8P5b_cAIIjcJ",
        "colab_type": "text"
      },
      "source": [
        "### 3.b - Create a class structure to save and analyse the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7xSVMRZoNkt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def computeentropy(image):\n",
        "  lensig=image.size\n",
        "  symset=list(set(image))\n",
        "  numsym=len(symset)\n",
        "  propab=[np.size(image[image==i])/(1.0*lensig) for i in symset]\n",
        "  ent=np.sum([p*np.log2(1.0/p) for p in propab])\n",
        "  return ent;\n",
        "\n",
        "class Digit:\n",
        "  def __init__(self, data, target):\n",
        "    self.width      = int(np.sqrt((len(data))))\n",
        "    self.target     = target;\n",
        "    self.image      = data;\n",
        "    \n",
        "    self.features   = {\n",
        "                        'var'        :0.0, 'std'        :0.0,\n",
        "                        'mean'       :0.0, 'entropy'    :0.0,\n",
        "                      }\n",
        "    self.computeFeatures()\n",
        "    \n",
        "  def computeFeatures(self):\n",
        "    self.features['var'] = round(np.var(self.image),2)\n",
        "    self.features['std'] = round(np.std(self.image),2)\n",
        "    self.features['mean'] = round(np.mean(self.image),2)\n",
        "    self.features['entropy'] = round(computeentropy(self.image),2)\n",
        "\n",
        "  def print(self):\n",
        "    print(\"Digit target: \" + str(self.target))\n",
        "    print(\"Digit target size: \"+ str(self.width)  + \"x\" +str(self.width) + \n",
        "          '| mean : ' + str(self.features['mean']) +\n",
        "          '| var : ' + str(self.features['var']) + \n",
        "          '| std :' + str(self.features['std']) + \n",
        "          '| entropy :' + str(self.features['entropy']))\n",
        "    print(\"Digit image:\")\n",
        "    plt.figure()\n",
        "    plt.gray()\n",
        "    plt.matshow(self.image.reshape(self.width, self.width)) \n",
        "    plt.savefig(str(self.target)+'.png', bbox_inches='tight')\n",
        "    plt.show() \n",
        "  def getWidth(self):\n",
        "    return self.width;\n",
        "\n",
        "\n",
        "class Dataset:    \n",
        "  def __init__(self, data, size=0, nb_classes=10):  \n",
        "    self.length = int((len(data['data'])))\n",
        "    if size > 0 and size <  self.length:\n",
        "      self.length = size;\n",
        "    else:\n",
        "      size = self.length;  \n",
        "\n",
        "    self.targets  = data['target'][0:size]\n",
        "    self.data = data['data'][0:size];\n",
        "    self.digits       = [];\n",
        "    self.nb_classes = nb_classes; \n",
        "    self.createDigits()\n",
        "    self.X_train = []; \n",
        "    self.X_test = []; \n",
        "    self.y_train = []; \n",
        "    self.y_test = [];  \n",
        "  \n",
        "  def printInfo(self):\n",
        "    from collections import Counter\n",
        "    \n",
        "    c = Counter(self.targets)\n",
        "    info = \"Dataset size \" + str(self.length)\n",
        "    key_value = {} \n",
        "    for i in sorted(c.keys()):\n",
        "      key_value[i] = c[i];\n",
        "     \n",
        "    plt.bar(key_value.keys(), key_value.values());\n",
        "    plt.xlabel('Labels')\n",
        "    plt.ylabel('Occurrence')\n",
        "    plt.title('Occurrence of MNIST dataset labels')\n",
        "    ax = plt.axes()        \n",
        "    ax.grid(which='major', axis='y')\n",
        "    plt.show()\n",
        "    return info\n",
        "  \n",
        "  def createDigits(self):\n",
        "    bar = progressbar.ProgressBar(maxval=self.length).start()\n",
        "    for i in range(self.length):\n",
        "        self.digits.append(Digit(self.data[i], self.targets[i]))\n",
        "        bar.update(i+1);\n",
        "\n",
        "  def separate_train_test(self, test_size_ratio):\n",
        "    from sklearn.model_selection import train_test_split \n",
        "    import keras\n",
        "\n",
        "    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(self.data, self.targets, test_size=test_size_ratio)\n",
        "    # data normalization   \n",
        "    self.X_train = self.X_train.astype('float32')/255;\n",
        "    self.X_test  = self.X_test.astype('float32')/255;\n",
        "\n",
        "    \n",
        "    print('Size of training set : ' + str(len(self.y_train)) + ' / ' + str(len(self.data)));\n",
        "    print('Size of testing set : ' + str(len(self.y_test))+ ' / ' + str(len(self.data)));\n",
        "    self.X_train  = self.X_train.reshape(len(self.X_train), self.digits[0].getWidth()*self.digits[0].getWidth())  # reshape input from (28,28) to 784\n",
        "    self.X_test   = self.X_test.reshape(len(self.X_test), self.digits[0].width*self.digits[0].width)\n",
        "    \n",
        "   \n",
        "    self.Y_train = keras.utils.to_categorical(self.y_train, self.nb_classes)\n",
        "    self.Y_test = keras.utils.to_categorical(self.y_test, self.nb_classes)\n",
        "  \n",
        "  def reshapeinImage(self):\n",
        "    width = self.digits[0].width; \n",
        "    self.X_trainIm = self.X_train.reshape(self.X_train.shape[0], width, width, 1)\n",
        "    self.X_testIm  = self.X_test.reshape(self.X_test.shape[0], width, width, 1)\n",
        "    \n",
        "  def adddNoise(self, intensity=1):\n",
        "    self.X_trainIm_noisy = self.X_trainIm + intensity * np.random.normal(loc=0.0, scale=1.0, size=self.X_trainIm.shape) \n",
        "    self.X_testIm_noisy = self.X_testIm + intensity * np.random.normal(loc=0.0, scale=1.0, size=self.X_testIm.shape) \n",
        "\n",
        "    self.X_trainIm_noisy = np.clip(self.X_trainIm_noisy, 0., 1.)\n",
        "    self.X_testIm_noisy = np.clip(self.X_testIm_noisy, 0., 1.)\n",
        "\n",
        "\n",
        "\n",
        "  def display_train_test(self):\n",
        "    from collections import Counter\n",
        "\n",
        "    test = Counter(self.y_test)\n",
        "    train = Counter(self.y_train)\n",
        "    info = \"Dataset size \" + str(self.length) \n",
        "    \n",
        "    key_value_train = {};\n",
        "    key_value_test = {};\n",
        "    \n",
        "    for i in sorted(test.keys()):\n",
        "      key_value_test[i] = test[i];\n",
        "    for i in sorted(train.keys()):\n",
        "      key_value_train[i] = train[i];\n",
        "\n",
        "    p1 = plt.bar(key_value_train.keys(), key_value_train.values(), width=0.5);\n",
        "    p2 = plt.bar( key_value_test.keys(), key_value_test.values(), width=0.5, bottom=list(key_value_train.values()) ); \n",
        "    \n",
        "    plt.legend((p1[0], p2[0]), ('Training set', 'Test set'), loc='lower left')\n",
        "    plt.xlabel('Labels')\n",
        "    plt.ylabel('Occurrence')\n",
        "    plt.title('Occurrence of training and testing sets')\n",
        "    ax = plt.axes()        \n",
        "    ax.grid(which='major', axis='y')\n",
        "    plt.show();    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQnh_R2-hgGA",
        "colab_type": "text"
      },
      "source": [
        "### 3.b - Load the MNIST dataset in Dataset class and analyse it: \n",
        "1.   Load the dataset in Dataset class \n",
        "\n",
        "*samples* is the number of considered samples (sub-set) over 700000 of MNIST dataset, it enables faster training and testing\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Dz7IOpTSMci",
        "colab_type": "code",
        "outputId": "cf89ff1f-7c04-4b4f-8259-d0bb0b8f2303",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "samples = 0; # All pictures \n",
        "training_set  = Dataset(mnist, samples) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 99% (69966 of 70000) |################# | Elapsed Time: 0:01:02 ETA:   0:00:00"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JohTNLeqgrkl",
        "colab_type": "text"
      },
      "source": [
        "2.   Display some digist with corresponding features  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQyihOsBOt1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "samples_to_diplay = 1;\n",
        "for i in range(samples_to_diplay):\n",
        "  training_set.digits[i].print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_hFGBfUgvAC",
        "colab_type": "text"
      },
      "source": [
        "3.   Display digits repartitions with *printInfo* function of *Dataset* class\n",
        "\n",
        "*   Is the dataset well balanced ?\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9TXwibVPQrH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set.printInfo()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xezss3PAoNk3",
        "colab_type": "text"
      },
      "source": [
        "## 4 - **Dataset preparation**\n",
        "\n",
        "\n",
        "> The MNIST dataset is split to training and testing sets with the corresponding labels\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1qYmf-SCTZn",
        "colab_type": "text"
      },
      "source": [
        "### 4.a - Split the the MNIST dataset in training and testing sets \n",
        "\n",
        "*   Use *separate_train_test* function with a test set split ratio as parameter \n",
        "*   The test and train sets will be loaded in X_train and X_test lists and the corresponding labels in y_train and y_test lists. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brlpjx3-oNk4",
        "colab_type": "code",
        "outputId": "4308ec8d-167c-454e-8245-869617945608",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "test_ratio = 0.2;\n",
        "training_set.separate_train_test(test_ratio)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of training set : 56000 / 70000\n",
            "Size of testing set : 14000 / 70000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lh-Y6bSfU7v",
        "colab_type": "text"
      },
      "source": [
        "### 4.b - Display the repartition of the digits \n",
        "\n",
        "*   Use  *display_train_test* function to illustrate the digits' repartition \n",
        "*   Check whether the repartition ratio is correct \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPJBIqaCfV8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set.display_train_test()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bgHCavaoNlC",
        "colab_type": "text"
      },
      "source": [
        "## 5 - **Build an auto-encoder with dense layers**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dB16uNx_CtmQ",
        "colab_type": "text"
      },
      "source": [
        "### 5.a - Build an auto-encoder with one dense layer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-Th2xJkn9xT",
        "colab_type": "text"
      },
      "source": [
        "> Import keras module "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOBmouD3oFok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31d3lMcIoGbg",
        "colab_type": "text"
      },
      "source": [
        "> In this section you will \n",
        "\n",
        "1) bluid an auto-encoder with one dense layer \n",
        "\n",
        "2) Train the auto-encodeur "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ry9k4IIqoNlC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_dim = 784\n",
        "latent_dim = 32\n",
        "\n",
        "epochs=80\n",
        "batch_size=256\n",
        "\n",
        "\n",
        "input_img = Input(shape=(original_dim,))\n",
        "\n",
        "\n",
        "\n",
        "encoder_layer = Dense(latent_dim, activation='relu');\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "decoder_layer = Dense(original_dim, activation='sigmoid') \n",
        "decoded = decoder_layer(encoded)\n",
        "\n",
        "autoencoder = Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy') # you can also use MSE loss function \n",
        "\n",
        "encoder = Model(input_img, encoded)\n",
        "\n",
        "encoded_input = Input(shape=(latent_dim,))\n",
        "decoder = Model(encoded_input, decoder_layer(encoded_input))\n",
        "\n",
        "\n",
        "autoencoder.summary()\n",
        "\n",
        "logsNN1 = #TO DO train the model \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5HbAqvkEhNc",
        "colab_type": "text"
      },
      "source": [
        "> Draw the evolution of the loss function during the training on training set and testing set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiQBjE8jnI73",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "plt.plot(logsNN1.history['loss'], label='Error (testing data NN1)')\n",
        "plt.plot(logsNN1.history['val_loss'], label='Error (validation data NN1)')\n",
        "plt.title('Binary cross entropy loss function')\n",
        "plt.ylabel('Loss Error')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper right\")\n",
        "\n",
        "plt.grid()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVsarV7ncPGb",
        "colab_type": "text"
      },
      "source": [
        "> What is the number of trained parameters of this auto-encoder ?\n",
        "\n",
        "> is it supervised or unsupervised learning ?\n",
        "\n",
        "> What is the compression ratio enabled by this auto-encoder ? \n",
        "\n",
        "> Test the deep auto-encoder on testing set.\n",
        "\n",
        "> Display the ten first images (original and decoded).\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEb8hEERyujh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_imgs = encoder.predict(training_set.X_test)\n",
        "decoded_imgs = decoder.predict(encoded_imgs)\n",
        "# you can also use \n",
        "#decoded_imgs = autoencoder.predict(training_set.X_test); "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdjDHj_L4aPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plotDigits(n, decoded_imgs):\n",
        "  plt.figure(figsize=(20, 4))\n",
        "  for i in range(n):\n",
        "      # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(training_set.X_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # display reconstruction\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "  plt.show()\n",
        "\n",
        "plotDigits(10, decoded_imgs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsqJQ0-1_Djw",
        "colab_type": "text"
      },
      "source": [
        "> you can also print the outputs of the encoder encoded_imgs (latent variables) of the ten first digits "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z14i8d5U_Hbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 10  # how many digits we will display\n",
        "plt.figure(figsize=(16, 8))\n",
        "for i in range(n):\n",
        "    # display original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(encoded_imgs[i].reshape(8,4))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rplTrxfImLi2",
        "colab_type": "text"
      },
      "source": [
        "### 5.b - Build a deep auto-encoder with three dense layer\n",
        "\n",
        "> Define a deep auto-encoder with three dense layers of size: 128, 64, 32.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA445O0Qj9O_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_dim = 784\n",
        "intermediate_dim0 = 128\n",
        "intermediate_dim1 = 64\n",
        "latent_dim = 32\n",
        "\n",
        "# TO DO\n",
        "\n",
        "logsNN3 = autoencoderNN3.fit(training_set.X_train, training_set.X_train,\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=True,\n",
        "                validation_data=(training_set.X_test, training_set.X_test))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zg1CfdgHGKhe",
        "colab_type": "text"
      },
      "source": [
        "> Draw the evolution of the loss function during the training on training set and testing set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJTRKetImt8O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(logsNN1.history['loss'], label='Error (testing data NN1)')\n",
        "plt.plot(logsNN1.history['val_loss'], label='Error (validation data NN1)')\n",
        "plt.plot(logsNN3.history['loss'], label='Error (testing data NN3)')\n",
        "plt.plot(logsNN3.history['val_loss'], label='Error (validation data NN3)')\n",
        "plt.title('Binary cross entropy loss function')\n",
        "plt.ylabel('Loss Error')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5Pq5HoqdPar",
        "colab_type": "text"
      },
      "source": [
        "> What is the number of trained parameters of this auto-encoder.\n",
        "\n",
        "> What is the compression ration enabled by this auto-encoder. \n",
        "\n",
        "> Test the deep auto-encoder on testing set \n",
        "\n",
        "> Display the ten first image (original and decoded).\n",
        "\n",
        " \n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pORmkwy-gmOc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoded_imgsNN3 = autoencoderNN3.predict(training_set.X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quSf1La9iNVY",
        "colab_type": "text"
      },
      "source": [
        "> Print the ten first images in testing set with the decoded onces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3nO61shuhjF_",
        "colab": {}
      },
      "source": [
        "plotDigits(10, decoded_imgsNN3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUWBI9jYpetQ",
        "colab_type": "text"
      },
      "source": [
        "### 5.c - Build a deep auto-encoder with only conv layers\n",
        "\n",
        "> Define a deep auto-encoder with two conv layers both composed of 32 features and kernel of size (3,3) followed by MaxPooling2D((2, 2), padding='same') (/2) for encoder and UpSampling2D((2, 2)) (*2) for the decoder.  Add last layer with 1 feature, (3,3) kernel and a sigmoid activation function.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6j37KpQE8vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "training_set.reshapeinImage()\n",
        "\n",
        "\n",
        "\n",
        "# TO DO \n",
        "logsConv = autoencoderConv.fit(training_set.X_trainIm, training_set.X_trainIm,\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=True,\n",
        "                validation_data=(training_set.X_testIm, training_set.X_testIm))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xXYG7zKGhDl",
        "colab_type": "text"
      },
      "source": [
        "> Print the evolution of the loss function during the training on training set and testing set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW5-D445Grdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(logsNN1.history['loss'], label='Error (testing data NN1)')\n",
        "plt.plot(logsNN1.history['val_loss'], label='Error (validation data NN1)')\n",
        "plt.plot(logsNN3.history['loss'], label='Error (testing data NN3)')\n",
        "plt.plot(logsNN3.history['val_loss'], label='Error (validation data NN3)')\n",
        "plt.plot(logsConv.history['loss'], label='Error (testing data) Conv')\n",
        "plt.plot(logsConv.history['val_loss'], label='Error (validation data) Conv')\n",
        "plt.title('Binary cross entropy loss function')\n",
        "plt.ylabel('Loss Error')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JDNu_QT7v6J",
        "colab_type": "text"
      },
      "source": [
        "> Test the Conv auto-encoder on testing set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1NK-ymmLRDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoded_imgsConv = autoencoderConv.predict(training_set.X_testIm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWDfWn047hec",
        "colab_type": "text"
      },
      "source": [
        "> Print the ten first images in testing set with the decoded onces."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg18biNQLLH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotDigits(10, decoded_imgsConv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13LoqSDrnmI1",
        "colab_type": "text"
      },
      "source": [
        "> What do you think about the quality of the reconstructed images, compare with those of previous auto-encoders "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0HYJCk-vWMa",
        "colab_type": "text"
      },
      "source": [
        "## 6- Application to image denoising\n",
        "\n",
        "> Add noise to the testing sets and try to denoise with the prevous auto-encoder\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ypeXFSgYc41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Noiseintensity = 0.5;\n",
        "training_set.adddNoise(Noiseintensity);\n",
        "decoded_imgsNoise = autoencoderConv.predict(training_set.X_testIm_noisy)\n",
        "# Denoise training_set.X_testIm_noisy\n",
        "# TO DO \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBWnelwTn3sv",
        "colab_type": "text"
      },
      "source": [
        "> Illustrate the 10 images before and after denoising process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB7qmgzmn09V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotDigits(10, decoded_imgsNoise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqb630nNiAWT",
        "colab_type": "text"
      },
      "source": [
        "> Now, you can define and train the last auto-encoder to perform denoising"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWNIDL0Gi9Wl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# TO DO\n",
        "# Define the conv auto-encoder model and train it for denoising \n",
        "\n",
        "logsconvDen = autoencoderConvDenoise.fit(# TO DO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN2nJbwFjbDP",
        "colab_type": "text"
      },
      "source": [
        "> Denoise the testing set \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHR13UGnoIiX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "decoded_imgsConvNoise = autoencoderConvDenoise.predict(training_set.X_testIm_noisy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkXJy-4aoJX8",
        "colab_type": "text"
      },
      "source": [
        "> Illustrate the 10 images before and after denoising process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKh0I36_jfNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plotDigits(10, decoded_imgsConvNoise)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBo4QZgyd2Xz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(logsConv.history['loss'], label='MAE (testing data) Conv')\n",
        "plt.plot(logsConv.history['val_loss'], label='MAE (validation data) Conv')\n",
        "plt.plot(logsconvDen.history['loss'], label='MAE (testing data) Conv denoise')\n",
        "plt.plot(logsconvDen.history['val_loss'], label='MAE (validation data) Conv denoise')\n",
        "plt.title('MAE for Chennai Reservoir Levels')\n",
        "plt.ylabel('MAE value')\n",
        "plt.xlabel('No. epoch')\n",
        "plt.legend(loc=\"upper right\")\n",
        "\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lseCqxJvo___",
        "colab_type": "text"
      },
      "source": [
        "## 7- Variational auto-encoder (VAE)\n",
        "\n",
        "> In this section you will build a variational auto-encoder with two dense layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZKVYKOOSzaX",
        "colab_type": "text"
      },
      "source": [
        "> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx8lOjwdoep5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "original_dim = 784\n",
        "intermediate_dim = 64\n",
        "latent_dim = 32\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "class Sampling(layers.Layer):\n",
        "  \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "  def call(self, inputs):\n",
        "    z_mean, z_log_var = inputs\n",
        "    batch = tf.shape(z_mean)[0]\n",
        "    dim = tf.shape(z_mean)[1]\n",
        "    epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "    return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "# Define encoder model.\n",
        "original_inputs = tf.keras.Input(shape=(original_dim,), name='encoder_input')\n",
        "x = layers.Dense(intermediate_dim, activation='relu')(original_inputs)\n",
        "z_mean = layers.Dense(latent_dim, name='z_mean')(x)\n",
        "z_log_var = layers.Dense(latent_dim, name='z_log_var')(x)\n",
        "z = Sampling()((z_mean, z_log_var))\n",
        "encoder = tf.keras.Model(inputs=original_inputs, outputs=z, name='encoder')\n",
        "\n",
        "# Define decoder model.\n",
        "latent_inputs = tf.keras.Input(shape=(latent_dim,), name='z_sampling')\n",
        "#TO DO \n",
        "\n",
        "# Define VAE model.\n",
        "outputs = decoder(z)\n",
        "vae = tf.keras.Model(inputs=original_inputs, outputs=outputs, name='vae')\n",
        "\n",
        "# Add KL divergence regularization loss.\n",
        "kl_loss = - 0.5 * tf.reduce_mean(\n",
        "    z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
        "vae.add_loss(kl_loss)\n",
        "\n",
        "# Train.\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "vae.compile(optimizer, loss=tf.keras.losses.MeanSquaredError())\n",
        "\n",
        "vae.fit(training_set.X_train, training_set.X_train, epochs=20, batch_size=128)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5q1t7qAJ16S",
        "colab_type": "text"
      },
      "source": [
        "> Denerate new digits with the generative decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWTsnC481IWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n = 15  # how many digits we will display\n",
        "figure = np.zeros((digit_size * n, digit_size * n))\n",
        "digit_size = 28\n",
        "    # linearly spaced coordinates corresponding to the 2D plot\n",
        "    # of digit classes in the latent space\n",
        "grid_x = np.linspace(-15, 15, n)\n",
        "grid_y = np.linspace(-15, 15, n)[::-1]\n",
        "\n",
        "epsilon   = K.random_normal(shape=(1, 32))\n",
        "for  i, yi in enumerate(grid_y):\n",
        "  for j, xi in enumerate(grid_x):\n",
        "   \n",
        "    z_sample  = np.array([[xi, yi]*16]) * epsilon\n",
        "    x_decoded = decoder.predict(z_sample)\n",
        "    digit     = x_decoded.reshape(digit_size, digit_size)\n",
        "    figure[i * digit_size: (i + 1) * digit_size,\n",
        "               j * digit_size: (j + 1) * digit_size] = digit\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.imshow(figure, cmap='Spectral')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}